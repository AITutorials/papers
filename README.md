
![Logo](http://www.tisv.cn/img/logo.png)
[![Build Status](http://www.tisv.cn/img/badge.svg)](http://www.tisv.cn/)    

--------------------------------------------------------------------------------

### 论文解析说明

以下论文均来自人工智能领域[SOTA](https://paperswithcode.com/sota)排行榜的精选论文，它们代表学术界最新的研究方向与成果，是AI未来的前进的方向。论文解析过程将阐述论文的摘要，核心论点，实验效果和说明等重要信息，并指引论文实现的Github地址。

---


### 精选论文解析

####  1. Understanding Back-Translation at Scale

当前在WMT2014英语到德语翻译集上表现最好的机器翻译模型是Transformer Big，其模型在提升中使用的技巧BT(Back-Translation)正是源自于该论文。

**[点击查看](https://arxiv.org/pdf/1808.09381v2.pdf)**



---


## 其他资源

* [Datasets(集成世界范围内的免费数据集和数据站点)](https://github.com/AITutorials/datasets)

* [Solutions(集成世界范围内重要AI技术解决方案)](https://github.com/AITutorials/solutions)

* [Manuals(解析真实企业的AI面试问题)](https://github.com/AITutorials/examples)

---


### 致谢

感谢以下机构或站点提供的人工智能工具和参考学习资料。所有人可以通过点击下方图片阅读免费电子书籍或访问这些机构的官方站点。


| [![avatar](http://ai.tisv.cn/img/book11.png)](https://livebook.manning.com/book/deep-learning-with-python/) | [![avatar](https://user-images.githubusercontent.com/61530230/76381930-e7e25900-6391-11ea-861a-5ceebb96d4bd.png)](https://www.deeplearningbook.org/contents/TOC.html) | [![avatar](http://ai.tisv.cn/img/book13.png)](http://neuralnetworksanddeeplearning.com/)|
| ---- | ---- | ---- |
| [![avatar](http://ai.tisv.cn/img/t1.png)](https://tensorflow.google.cn/) |  [![avatar](http://ai.tisv.cn/img/t2.png)](https://pytorch.org/) | [![avatar](http://ai.tisv.cn/img/t3.png)](https://keras.io/) |
